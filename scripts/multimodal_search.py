import faiss
import numpy as np
import json


class MultimodalSearcher:
    def __init__(self):
        # åŠ è½½èµ„æº
        self.index = faiss.read_index("output/unified/multimodal_index.faiss")
        with open("output/unified/metadata.json") as f:
            self.meta = json.load(f)

        # åŠ è½½è·¯å¾„æ•°æ®
        self.image_paths = np.load("output/image_paths.npy")
        self.text_labels = np.load("output/text_vectors/emotion_labels.npy")
        self.audio_paths = np.load("output/audio_vectors/audio_paths.npy")

    def search_by_image(self, image_path, top_k=3):
        """æ ¸å¿ƒåŠŸèƒ½ï¼šå›¾ç‰‡â†’åŒ¹é…å›¾ç‰‡â†’å¯¹åº”éŸ³é¢‘"""
        from clip_feature_extractor import extract_features

        # 1. æå–æŸ¥è¯¢å›¾ç‰‡å‘é‡
        query_vec = extract_features(image_path)
        query_vec = np.load("output/unified/image_vecs_20d.npy")[0]  # ç¤ºä¾‹ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡

        # 2. åœ¨ç»Ÿä¸€ç´¢å¼•ä¸­æœç´¢
        d, i = self.index.search(query_vec.reshape(1, -1), top_k)

        # 3. ç»“æœè§£æ
        results = []
        for idx, score in zip(i[0], d[0]):
            if idx <= self.meta["image_range"][1]:
                # å›¾ç‰‡ç»“æœ
                img_path = self.image_paths[idx]
                audio_idx = np.where(self.audio_paths == img_path.replace(".jpg", ".mp3"))[0]
                if len(audio_idx) > 0:
                    results.append({
                        "type": "image",
                        "path": img_path,
                        "audio": self.audio_paths[audio_idx[0]],
                        "score": float(score)
                    })
        return results


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    searcher = MultimodalSearcher()
    results = searcher.search_by_image("test.jpg")  # æ›¿æ¢ä¸ºä½ çš„æµ‹è¯•å›¾ç‰‡è·¯å¾„

    print("ğŸ† åŒ¹é…ç»“æœï¼š")
    for res in results:
        print(f"å›¾ç‰‡: {res['path']}")
        print(f"éŸ³é¢‘: {res['audio']}")
        print(f"ç›¸ä¼¼åº¦: {res['score']:.4f}\n")